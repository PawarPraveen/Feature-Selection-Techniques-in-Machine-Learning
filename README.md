# Feature Selection Techniques in Machine Learning

This repository demonstrates various **feature selection techniques** for improving machine learning models by reducing dimensionality, removing irrelevant features, and enhancing performance.

##  Overview

Feature selection is a crucial preprocessing step in machine learning that:
- Reduces overfitting
- Improves model accuracy
- Decreases computational cost
- Enhances interpretability

This notebook explores multiple feature selection methods, with code examples and explanations.

---

##  Contents

- **Filter Methods**  
  - Correlation-based selection
  - Chi-square test
  - Mutual information

- **Wrapper Methods**  
  - Recursive Feature Elimination (RFE)
  - Forward/Backward Selection

- **Embedded Methods**  
  - Lasso (L1) Regularization
  - Ridge (L2) Regularization
  - Tree-based feature importance (RandomForest, XGBoost)

---


